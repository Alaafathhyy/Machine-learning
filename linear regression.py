# -*- coding: utf-8 -*-
"""final modification on assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c8RtfQBo6tKgiwl7DY76n8FovHXcbcNe
"""

import pandas as pd

data=pd.read_csv("/content/diabetic_kidney_disease (1).csv")

data.head()

import numpy as np

normalized_data=(data-data.min())/(data.max()-data.min())

normalized_data.head()

normalized_data.isnull().sum()

normalized_data.insert(0,'one',1)



df=normalized_data

df.head()

X = df.iloc[:, 0:2].values
Y = df.iloc[:, -1].values

X.shape

X_train = X[:89]
Y_train = Y[:89]

X_test = X[89:]
Y_test = Y[89:]

X_train.shape

X_train = np.matrix(X_train)
Y_train = np.matrix(Y_train)
X_test = np.matrix(X_test)
Y_test = np.matrix(Y_test)

X_test.shape

c=np.matrix(np.array([0,0]))

c.shape

import numpy
#this function claculate the cost function (error)
def MSE(X_train,Y_train,c):
    h_x=np.dot(X_train,c.transpose())
    s=np.power(h_x-Y_train,2)
    return np.sum(s)/(2*len(X_train))

loss=MSE(X_train,Y_train,c)

print("loss function = " ,loss)

alpha=0.005
n_iterations=20

import numpy as np
#this function calculate the gradient descent algorithm 
def G_D(X_train,Y_train,c,alpha,n_iterations):
    temp=np.matrix(np.zeros(c.shape))
    n_weights=2
    cost=np.zeros(n_iterations)
    for i in range (n_iterations):
        h_x=np.dot(X_train,c.transpose())
        error=h_x-Y_train
        for j in range (n_weights):
            v=np.multiply(error,X_train[:,j])
            temp[0,j]=temp[0,j]-((alpha/len(X_train))*np.sum(v))
        c=temp
        cost[i]=MSE(X_train,Y_train,c)
    return c,cost

parameters,loss=G_D(X_train,Y_train,c,alpha,n_iterations)

print("the weights after all the iterations = ",parameters)

n_iters=20
# this foor loop tries different values of alpha 
z=np.array([0.001,0.002,0.003,0.004,0.005])
for alpha2 in  z:
  weights,cost=G_D(X_train,Y_train,c,alpha2,n_iters)
  print("with aplpha = ",alpha2 ,"the cost will be ",cost)

print("cost after the iterations with alpha =0.005 and number of iterations=20  ",loss)

print("loss function of test data = " , MSE(X_test,Y_test,parameters))

import matplotlib.pyplot as plt

#this function the same as the first one but it returns also h(X) 
def MSE2(X_train,Y_train,c):
    h_x=np.dot(X_train,c.transpose())
    s=np.power(Y_train-h_x,2)
    return np.sum(s)/(2*len(X_train)),h_x

plt.scatter([X_test[:,1]],[Y_test[:]])
losss,y_pred=MSE2(X_test,Y_test,parameters)
plt.plot(X_test,y_pred)

plt.scatter([X[:,1]],[Y[:]])
losss,y_pred=MSE2(X_test,Y_test,parameters)
plt.plot(X_test,y_pred)